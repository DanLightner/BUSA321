{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQtaNKl8ONNj"
      },
      "source": [
        "# OCR with PyTesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Vn-VENONNk",
        "outputId": "24f60b99-9529-40a9-f96c-5a3aaf12b5ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'pip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract\n",
        "# Also, install the .exe file here: https://github.com/UB-Mannheim/tesseract/wiki"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**NOTE**: If using on your own machine, install the .exe file here: https://github.com/UB-Mannheim/tesseract/wiki and you do not need to install the *!sudo apt install tesseract-ocr*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytesseract'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytesseract\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytesseract'"
          ]
        }
      ],
      "source": [
        "import pytesseract\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOMDH9s0ONNm",
        "outputId": "d4a37e3c-788b-486c-f01f-567e8edeea49"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "try:\n",
        "  from PIL import Image\n",
        "except ImportError:\n",
        "  import Image\n",
        "\n",
        "# Use this if installed on your local computer\n",
        "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Read in the images**: This will take the images from your folder and read them, just like reading DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "images\\3_1238858492653551617.jpg:\n",
            "\n",
            "images\\3_1238858492653551617.jpg_processed.jpg:\n",
            "99\n",
            ":\n",
            "\n",
            "CHOCO!\n",
            "\n",
            "\n",
            "images\\3_1240664487151181824.jpg:\n",
            "\n",
            "images\\3_1240664487151181824.jpg_processed.jpg:\n",
            "\n",
            "images\\3_1241934859922223105.jpg:\n",
            "\n",
            "images\\3_1241934859922223105.jpg_processed.jpg:\n",
            "\n",
            "images\\3_1243139422608113664.jpg:\n",
            "\n",
            "images\\3_1243139422608113664.jpg_processed.jpg:\n",
            "\n",
            "images\\3_1243174640165572609.jpg:\n",
            "How effective is vaccination?\n",
            "\n",
            "Diphtheria cases | Introduction of vaccine\n",
            "\n",
            "Pertussis cases Introduction of vaccine\n",
            "\n",
            "+ $@0 «Gia Pregpcewe-se-+6-\n",
            "\n",
            "1940\n",
            "\n",
            "Measles cases Introduction of vaccine\n",
            "eecccccoccce\n",
            "\n",
            "i\n",
            "1968 2013\n",
            "\n",
            "immunologg\n",
            "#CelebrateVaccines g\n",
            "www.immunology.org\n",
            "\n",
            "\n",
            "images\\3_1243174640165572609.jpg_processed.jpg:\n",
            "How effective is vaccination?\n",
            "\n",
            "Diphtheria cases ij Introduction of vaccine\n",
            "\n",
            "Pertussis cases Introduction of vaccine\n",
            "\n",
            "+ $@0 <I Preglecewe-se-+6-\n",
            "\n",
            "1940\n",
            "\n",
            "Measles cases Introduction of vaccine\n",
            "eecccccoccce\n",
            "\n",
            "i\n",
            "1968 2013\n",
            "\n",
            "immunologg\n",
            "#CelebrateVaccines g\n",
            "www.immunology.org\n",
            "\n",
            "\n",
            "images\\3_1243598390782558208.jpg:\n",
            "TAKE CARE\n",
            "\n",
            "OF YouRsELF\n",
            "\n",
            "images\\3_1243598390782558208.jpg_processed.jpg:\n",
            "TAKE CARE\n",
            "\n",
            "OF YouRsELF\n",
            "\n",
            "images\\3_1245345030891593728.jpg:\n",
            "Take Breaks\n",
            "\n",
            "Make time to unplug and decrease\n",
            "sensory overload. Try to turn to\n",
            "activities you enjoy - listen to music,\n",
            "take a walk, watch a favorite TV show.\n",
            "\n",
            "\n",
            "images\\3_1245345030891593728.jpg_processed.jpg:\n",
            "Take Breaks\n",
            "\n",
            "Make time to unplug and decrease\n",
            "sensory overload. Try to turn to\n",
            "activities you enjoy - listen to music,\n",
            "take a walk, watch a favorite TV show.\n",
            "\n",
            "\n",
            "images\\3_1245798441667657730.jpg:\n",
            "\n",
            "images\\3_1245798441667657730.jpg_processed.jpg:\n",
            "\n",
            "images\\3_1245954197876396032.jpg:\n",
            "Tips for\n",
            "autistic\n",
            "people\n",
            "and\n",
            "families\n",
            "\n",
            "\n",
            "images\\3_1245954197876396032.jpg_processed.jpg:\n",
            "Tips for\n",
            "autistic\n",
            "people\n",
            "and\n",
            "families\n",
            "\n",
            "\n",
            "images\\3_1246820149719638016.jpg:\n",
            "\n",
            "images\\3_1246820149719638016.jpg_processed.jpg:\n",
            "\n",
            "images\\3_1247543425324535809.jpg:\n",
            "Coping with\n",
            "Coronavirus\n",
            "\n",
            "\n",
            "images\\3_1247543425324535809.jpg_processed.jpg:\n",
            "Coping with |\n",
            "Coronavirus\n",
            "\n",
            "\n",
            "images\\3_1249002051377520642.jpg:\n",
            "PA\n",
            "ma\n",
            "\n",
            "“hah\n",
            "\n",
            "HAPPENING NOW\n",
            "\n",
            "Province now has a total of 4,726 cases of coronavirus and 153 deaths\n",
            "\n",
            "images\\3_1250520017269149697.jpg:\n",
            "\n",
            "images\\3_1250774094410375168.jpg:\n",
            "\n",
            "images\\3_1252998618228969482.jpg:\n",
            "\n",
            "images\\3_1254712400596647936.jpg:\n",
            "mse it\n",
            "\n",
            "Understanding the impact on\n",
            "autistic employees\n",
            "\n",
            "i eo ee ea\n",
            "\n",
            "images\\3_1256130805883166720.jpg:\n",
            "We are all havingito change\n",
            "e way we do things :\n",
            "\n",
            "cause of c avirus a\n",
            "] ust to m istresses. \\\n",
            "\n",
            "id-195 SS, LONDON\n",
            "#Londonfegether . es ILS 2\n",
            "\n",
            "\n",
            "images\\3_1258317151406108673.png:\n",
            "\n",
            "images\\3_1259741400838668288.jpg:\n",
            "\n",
            "images\\3_1259995460586127363.jpg:\n",
            "0 meres\n",
            "\n",
            "7) iE i\n",
            "\n",
            "ily o\n",
            "\n",
            "nes i\n",
            "\n",
            "i |\n",
            "\n",
            "x .\n",
            "| Ble: : \\J [)\n",
            "\n",
            "images\\3_1260313022263971842.jpg:\n",
            "\n",
            "images\\3_1260742033687314435.jpg:\n",
            "\n",
            "images\\3_1260826931316109313.jpg:\n",
            "\n",
            "images\\3_1261218603774418944.jpg:\n",
            "\n",
            "images\\3_1264196280865226759.jpg:\n",
            "\n",
            "images\\3_1265285332251095042.jpg:\n",
            "\n",
            "images\\3_1265408648425209859.jpg:\n",
            "oa\n",
            "\n",
            "LIVING IN A STATE OF UNCERTAINTY\n",
            "\n",
            "images\\3_1265565950444810241.jpg:\n",
            "\n",
            "images\\3_1265635193588760582.jpg:\n",
            "\n",
            "images\\3_628913364622688256.jpg:\n",
            "\n",
            "images\\3_628933195636047872.jpg:\n",
            "\n",
            "images\\3_705230045120503808.jpg:\n",
            "\n",
            "images\\3_743191718107852801.jpg:\n",
            "Abstract + Send to: ~\n",
            "\n",
            "J Health Popul Nutr. 2014 Jun;32(2):367-71.\n",
            "Cerebral atrophy in a vitamin B12-deficient infant of a vegetarian mother.\n",
            "\n",
            "Abstract\n",
            "\n",
            "In developed countries, vitamin B12 (cobalamin) deficiency usually occurs in children, exclusively breastfed ones whose mothers are\n",
            "vegetarian, causing low body stores of vitamin B12. The haematologic manifestation of vitamin B12 deficiency is pernicious anaemia.\n",
            "It is a megaloblastic anaemia with high mean corpuscular volume and typical morphological features, such as hyperlobulation of the\n",
            "nuclei of the granulocytes. In advanced cases, neutropaenia and thrombocytopaenia can occur, simulating aplastic anaemia or\n",
            "leukaemia. In addition to haematological symptoms, infants may experience weakness, fatigue, failure to thrive, and irritability. Other\n",
            "common findings include pallor, glossitis, vomiting, diarrhoea, and icterus. Neurological symptoms may affect the central nervous\n",
            "system and, in severe cases, rarely cause brain atrophy. Here, we report an interesting case, a 12-month old infant, who was admitted\n",
            "with neurological symptoms and diagnosed with vitamin B12 deficiency.\n",
            "\n",
            "PMID: 25076673 [PubMed - indexed for MEDLINE] PMCID: PMC4216972_ Free PMC Article\n",
            "Hy» Si\n",
            "\n",
            "Images from this publication. See all images (3) Free text cy\n",
            "\n",
            "\n",
            "images\\3_820102081516187648.jpg:\n",
            "\n",
            "images\\3_942575276852240385.jpg:\n",
            "A MOTHER, HER AUTISTIC SON, The author writes about her son:\n",
            "AND THE KINDNESS\n",
            "\n",
            "OR MACHINES \"Il am still deeply worried\n",
            "\n",
            "about the idea that he could\n",
            "get someone pregnant and\n",
            "yet could never be a real\n",
            "father -which is why | will\n",
            "insist on having medical\n",
            "power of attorney, so that\n",
            "\n",
            "| will be able to make the\n",
            "decision about a vasectomy\n",
            "for him after he turns 18.”\n",
            "\n",
            "Please share and join the\n",
            "\n",
            "siete #BoycottToSiri\n",
            "\n",
            "images\\3_975116043684265984.jpg:\n",
            "\n",
            "images\\3_986237477957484545.jpg:\n",
            "\n",
            "images\\desktop.ini\n"
          ]
        }
      ],
      "source": [
        "# Make sure your images folder is saved in the same folder as this .ipynb file\n",
        "\n",
        "pathlist = Path('images/').glob('*.*')\n",
        "for i, path in enumerate(pathlist):\n",
        "  path_in_str = str(path)\n",
        "  try:\n",
        "    print(f'{path_in_str}:\\n{pytesseract.image_to_string(path_in_str)}')\n",
        "  except:\n",
        "    print(f'{path_in_str}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Extracting text**: The following will create a DataFrame of extracted words from each of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "75enUzLcjIzp",
        "outputId": "5fb90bd3-ee5e-47cc-95e8-e39a3455a15f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>3_1265408648425209859.jpg</td>\n",
              "      <td>oa LIVING IN A STATE OF UNCERTAINTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3_1254712400596647936.jpg</td>\n",
              "      <td>mse it Understanding the impact on autistic em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3_1256130805883166720.jpg</td>\n",
              "      <td>We are all havingito change e way we do things...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3_1245954197876396032.jpg</td>\n",
              "      <td>Tips for autistic people and families</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3_1245954197876396032.jpg_processed.jpg</td>\n",
              "      <td>Tips for autistic people and families</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      image  \\\n",
              "37                3_1265408648425209859.jpg   \n",
              "26                3_1254712400596647936.jpg   \n",
              "27                3_1256130805883166720.jpg   \n",
              "16                3_1245954197876396032.jpg   \n",
              "17  3_1245954197876396032.jpg_processed.jpg   \n",
              "\n",
              "                                                 text  \n",
              "37               oa LIVING IN A STATE OF UNCERTAINTY   \n",
              "26  mse it Understanding the impact on autistic em...  \n",
              "27  We are all havingito change e way we do things...  \n",
              "16             Tips for autistic people and families   \n",
              "17             Tips for autistic people and families   "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.DataFrame(columns=['image', 'text'])\n",
        "\n",
        "# Change this to your path. If you are working on your own machine, then the path will simply be 'images/'\n",
        "\n",
        "pathlist = Path('images/').glob('*.*')\n",
        "for i, path in enumerate(pathlist):\n",
        "  path_in_str = str(path)\n",
        "  id = path.name # The path object is not a string so we need to use the name attribute\n",
        "\n",
        "  try:\n",
        "    text = pytesseract.image_to_string(path_in_str)\n",
        "  except:\n",
        "    text = \"\"\n",
        "  # The re package allows us to use regex to remove tabs, extra spaces, and line breaks\n",
        "  df.loc[i] = [id, re.sub('\\s+',' ', text)]\n",
        "\n",
        "df.to_csv('image_text.csv')\n",
        "df.sort_values(by=['text'], ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create a new DataFrame** with only images that *have text*. From this, you can use any analysis tools you have learned so far for DataFrames. You can use this to see what kinds of text are appearing in your images or filter your data even further.  **Try it out!**\n",
        "\n",
        "**ACTIVITY**: While regression and categorical analysis may not be the best option for this data, what kind of analysis could you use on this dataset? Are there ways to filter out and find patterns among the text?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3_1238858492653551617.jpg_processed.jpg</td>\n",
              "      <td>99 : CHOCO!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3_1243174640165572609.jpg</td>\n",
              "      <td>How effective is vaccination? Diphtheria cases...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3_1243174640165572609.jpg_processed.jpg</td>\n",
              "      <td>How effective is vaccination? Diphtheria cases...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3_1243598390782558208.jpg</td>\n",
              "      <td>TAKE CARE OF YouRsELF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3_1243598390782558208.jpg_processed.jpg</td>\n",
              "      <td>TAKE CARE OF YouRsELF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3_1245345030891593728.jpg</td>\n",
              "      <td>Take Breaks Make time to unplug and decrease s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3_1245345030891593728.jpg_processed.jpg</td>\n",
              "      <td>Take Breaks Make time to unplug and decrease s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3_1245954197876396032.jpg</td>\n",
              "      <td>Tips for autistic people and families</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3_1245954197876396032.jpg_processed.jpg</td>\n",
              "      <td>Tips for autistic people and families</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3_1247543425324535809.jpg</td>\n",
              "      <td>Coping with Coronavirus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3_1247543425324535809.jpg_processed.jpg</td>\n",
              "      <td>Coping with | Coronavirus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3_1249002051377520642.jpg</td>\n",
              "      <td>PA ma “hah HAPPENING NOW Province now has a to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3_1254712400596647936.jpg</td>\n",
              "      <td>mse it Understanding the impact on autistic em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3_1256130805883166720.jpg</td>\n",
              "      <td>We are all havingito change e way we do things...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>3_1259995460586127363.jpg</td>\n",
              "      <td>0 meres 7) iE i ily o nes i i | x . | Ble: : \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>3_1265408648425209859.jpg</td>\n",
              "      <td>oa LIVING IN A STATE OF UNCERTAINTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3_743191718107852801.jpg</td>\n",
              "      <td>Abstract + Send to: ~ J Health Popul Nutr. 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>3_942575276852240385.jpg</td>\n",
              "      <td>A MOTHER, HER AUTISTIC SON, The author writes ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      image  \\\n",
              "1   3_1238858492653551617.jpg_processed.jpg   \n",
              "8                 3_1243174640165572609.jpg   \n",
              "9   3_1243174640165572609.jpg_processed.jpg   \n",
              "10                3_1243598390782558208.jpg   \n",
              "11  3_1243598390782558208.jpg_processed.jpg   \n",
              "12                3_1245345030891593728.jpg   \n",
              "13  3_1245345030891593728.jpg_processed.jpg   \n",
              "16                3_1245954197876396032.jpg   \n",
              "17  3_1245954197876396032.jpg_processed.jpg   \n",
              "20                3_1247543425324535809.jpg   \n",
              "21  3_1247543425324535809.jpg_processed.jpg   \n",
              "22                3_1249002051377520642.jpg   \n",
              "26                3_1254712400596647936.jpg   \n",
              "27                3_1256130805883166720.jpg   \n",
              "30                3_1259995460586127363.jpg   \n",
              "37                3_1265408648425209859.jpg   \n",
              "43                 3_743191718107852801.jpg   \n",
              "45                 3_942575276852240385.jpg   \n",
              "\n",
              "                                                 text  \n",
              "1                                        99 : CHOCO!   \n",
              "8   How effective is vaccination? Diphtheria cases...  \n",
              "9   How effective is vaccination? Diphtheria cases...  \n",
              "10                             TAKE CARE OF YouRsELF   \n",
              "11                             TAKE CARE OF YouRsELF   \n",
              "12  Take Breaks Make time to unplug and decrease s...  \n",
              "13  Take Breaks Make time to unplug and decrease s...  \n",
              "16             Tips for autistic people and families   \n",
              "17             Tips for autistic people and families   \n",
              "20                           Coping with Coronavirus   \n",
              "21                         Coping with | Coronavirus   \n",
              "22  PA ma “hah HAPPENING NOW Province now has a to...  \n",
              "26  mse it Understanding the impact on autistic em...  \n",
              "27  We are all havingito change e way we do things...  \n",
              "30  0 meres 7) iE i ily o nes i i | x . | Ble: : \\...  \n",
              "37               oa LIVING IN A STATE OF UNCERTAINTY   \n",
              "43  Abstract + Send to: ~ J Health Popul Nutr. 201...  \n",
              "45  A MOTHER, HER AUTISTIC SON, The author writes ...  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_text = df[df.text != '']\n",
        "df_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYsanOaWONNp"
      },
      "source": [
        "# Extract Entities: OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-i8qvj5ONNq",
        "outputId": "f7db7f13-35ee-4a47-bb1f-21e939e9078d"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Pretrained model**: Remember how we would split our data into training/testing data? This is called \"training the model.\" So, when we use a **pretrained model**, this means that the model has already been trained on previous similar data. \n",
        "\n",
        "List of pre-trained classifiers (models that *classify* images as being part of a face or not):\n",
        "* haarcascade_eye_tree_eyeglasses.xml   \n",
        "* haarcascade_eye.xml                   \n",
        "* haarcascade_frontalface_alt2.xml      \n",
        "* haarcascade_frontalface_alt_tree.xml  \n",
        "* haarcascade_frontalface_alt.xml       \n",
        "* haarcascade_frontalface_default.xml   \n",
        "* haarcascade_fullbody.xml              \n",
        "* haarcascade_lefteye_2splits.xml       \n",
        "* haarcascade_lowerbody.xml             \n",
        "* haarcascade_mcs_eyepair_big.xml       \n",
        "* haarcascade_mcs_eyepair_small.xml     \n",
        "* haarcascade_mcs_leftear.xml\n",
        "* haarcascade_mcs_lefteye.xml\n",
        "* haarcascade_mcs_mouth.xml\n",
        "* haarcascade_mcs_nose.xml\n",
        "* haarcascade_mcs_rightear.xml\n",
        "* haarcascade_mcs_righteye.xml\n",
        "* haarcascade_mcs_upperbody.xml\n",
        "* haarcascade_profileface.xml\n",
        "* haarcascade_righteye_2splits.xml\n",
        "* haarcascade_smile.xml\n",
        "* haarcascade_upperbody.xml\n",
        "\n",
        "\n",
        "**NOTE**: Make sure the .xml file is saved in the **same folder** as your .ipynb notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_bHzPa1BONNr",
        "outputId": "15400df3-6b56-498c-a2c4-43b50ca44bff"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the cascade from local machine\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the following code, which will pop up images in separate windows showing rectangles around various facial features. Notice the difference between the following codes: one focuses on facial features and the other adds eyes.\n",
        "\n",
        "**ACTIVITY 1**: Reference your book for specific scales that can be changed. Change some of these settings and see what you can do.\n",
        "\n",
        "**ACTIVITY 2**: Do a third set of image classification using one of the other pretrained classifiers above (NOTE: you will need to download this as well)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "desktop.ini: 0 faces\n",
            "desktop.ini: 0 faces\n",
            "desktop.ini: 0 faces\n",
            "desktop.ini: 0 faces\n",
            "desktop.ini: 2 faces\n"
          ]
        }
      ],
      "source": [
        "# Change this to your path. If you are working on your own machine, then the path will simply be 'images/'\n",
        "pathlist = Path('images/').glob('*.*')\n",
        "for i, path in enumerate(pathlist):\n",
        "  if i > 4:\n",
        "    break\n",
        "\n",
        "  path_in_str = str(path)\n",
        "\n",
        "  # Read the input image\n",
        "  img = cv2.imread(path_in_str)\n",
        "\n",
        "  # Convert into grayscale\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Detect faces\n",
        "  faces = face_cascade.detectMultiScale(image=gray, scaleFactor=1.3, minNeighbors=5)\n",
        "\n",
        "  # Draw rectangle around the faces\n",
        "  for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "  # Display the output\n",
        "  try:\n",
        "    cv2.imshow('img', img)\n",
        "    cv2.waitKey()\n",
        "  except:\n",
        "    cv2_imshow(img)\n",
        "\n",
        "\n",
        "  # status = cv2.imwrite('faces_detected.jpg', img) # We can save the images that have entities somewhere\n",
        "  print(f\"{id}: {len(faces)} faces\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oOzebv-xOzgl",
        "outputId": "1867d8cc-ed1e-46bc-eb1f-e87663766b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "desktop.ini: 4 faces\n",
            "desktop.ini: 7 faces\n",
            "desktop.ini: 4 faces\n",
            "desktop.ini: 6 faces\n",
            "desktop.ini: 3 faces\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the cascade from local machine\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "# Change this to your path. If you are working on your own machine, then the path will simply be 'images/'\n",
        "pathlist = Path('images/').glob('*.*')\n",
        "for i, path in enumerate(pathlist):\n",
        "  if i > 4:\n",
        "    break\n",
        "  path_in_str = str(path)\n",
        "\n",
        "  # Read the input image\n",
        "  img = cv2.imread(path_in_str)\n",
        "\n",
        "  # Convert into grayscale\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Detect faces\n",
        "  faces = face_cascade.detectMultiScale(image=gray, scaleFactor=1.05, minNeighbors=3)\n",
        "\n",
        "  # Detect eyes\n",
        "  eyes = eye_cascade.detectMultiScale(image=gray, scaleFactor=1.05, minNeighbors=3)\n",
        "\n",
        "  # Draw rectangle around the faces\n",
        "  for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "  # Draw rectangle around the eyes\n",
        "  for (x, y, w, h) in eyes:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "  # Display the output\n",
        "  try:\n",
        "    cv2.imshow('img', img)\n",
        "    cv2.waitKey()\n",
        "  except:\n",
        "    cv2_imshow(img)\n",
        "\n",
        "\n",
        "  # status = cv2.imwrite('faces_detected.jpg', img) # We can save the images that have entities somewhere\n",
        "  print(f\"{id}: {len(faces)} faces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Turn it into a DataFrame**: Put it all together into a DataFrame. Look at the full DataFrame (not just the head) in a separate code section. \n",
        "\n",
        "**ACTIVITY 1**: What kinds of analysis do you think would be useful for this type of data? Filter your dataset (such as text vs. non-text, number of face and eyes, etc.) and see if you find any patterns. \n",
        "\n",
        "**ACTIVITY 2**: Do some research on **haar cascade** for facial recognition. What is this algorithm? How does it work?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "saX_zUkcOz-j",
        "outputId": "93a18fc3-b5be-4b2a-dc3c-eddcdc44078f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>text</th>\n",
              "      <th>faces</th>\n",
              "      <th>eyes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>desktop.ini</td>\n",
              "      <td>oa LIVING IN A STATE OF UNCERTAINTY</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>desktop.ini</td>\n",
              "      <td>mse it Understanding the impact on autistic em...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>desktop.ini</td>\n",
              "      <td>We are all havingito change e way we do things...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>desktop.ini</td>\n",
              "      <td>Tips for autistic people and families</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>desktop.ini</td>\n",
              "      <td>Tips for autistic people and families</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          image                                               text faces eyes\n",
              "37  desktop.ini               oa LIVING IN A STATE OF UNCERTAINTY      0    3\n",
              "26  desktop.ini  mse it Understanding the impact on autistic em...     0    0\n",
              "27  desktop.ini  We are all havingito change e way we do things...     0    0\n",
              "16  desktop.ini             Tips for autistic people and families      2    3\n",
              "17  desktop.ini             Tips for autistic people and families      2    3"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "df = pd.DataFrame(columns=['image', 'text', 'faces', 'eyes'])\n",
        "\n",
        "# Load the cascade\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "# Change this to your path. If you are working on your own machine, then the path will simply be 'images/'\n",
        "pathlist = Path('images/').glob('*.*')\n",
        "for i, path in enumerate(pathlist):\n",
        "  path_in_str = str(path)\n",
        "\n",
        "  # OCR the text\n",
        "  try:\n",
        "    text = pytesseract.image_to_string(path_in_str)\n",
        "  except:\n",
        "    text = \"\"\n",
        "\n",
        "  # Read the input image\n",
        "  img = cv2.imread(path_in_str)\n",
        "\n",
        "  # Convert into grayscale\n",
        "  try:\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
        "    eyes = eye_cascade.detectMultiScale(gray, 1.3, 4)\n",
        "\n",
        "    # Draw rectangle around the faces\n",
        "    for (x, y, w, h) in faces:\n",
        "      cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) # Blue\n",
        "\n",
        "    # Draw rectangle around the eyes\n",
        "    for (x, y, w, h) in eyes:\n",
        "      cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2) # Green\n",
        "  except:\n",
        "    faces = []\n",
        "    eyes = []\n",
        "\n",
        "  # Display the output\n",
        "  try:\n",
        "    cv2.imshow('img', img)\n",
        "    cv2.waitKey()\n",
        "  except:\n",
        "    try:\n",
        "      cv2_imshow(img)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  df.loc[i] = [id, re.sub('\\s+',' ', text), len(faces), len(eyes)]\n",
        "\n",
        "df.to_csv('image_text.csv')\n",
        "df.sort_values(by=['text'], ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NzdP_OtONNs"
      },
      "source": [
        "# EXTRA: Tensorflow: Classify Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmQqi0Z1ONNs"
      },
      "source": [
        "## Load Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhG9HhZqONNt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPt-Pxu8ONNt"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "dataset_url = \"C:\\\\Users\\\\markk\\\\Google Drive\\\\Colab Notebooks\\\\research\\\\autism\\\\images\\\\\"\n",
        "data_dir = pathlib.Path(dataset_url)\n",
        "image_count = len(list(data_dir.glob('*.jpg'))) + len(list(data_dir.glob('*.png')))\n",
        "print(f'{image_count} total images')\n",
        "\n",
        "img = list(data_dir.glob('*'))\n",
        "PIL.Image.open(str(img[0]))\n",
        "PIL.Image.open(str(img[1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wWq-euSONNv"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QDqjwhHONNw"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az1DnJo0ONNw",
        "outputId": "efb2f3d6-ac92-4caa-907e-b5f5ef6f828e"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKonhAXlONNx"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFooipuHONNx"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkec0D0LONNy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "539ei11ZONNy"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeutNoguONNz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me5eHtgHONNz"
      },
      "outputs": [],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixels values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4GAn0I2ONNz"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pzqbEUaONN0"
      },
      "outputs": [],
      "source": [
        "num_classes = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OANAu-TwONN0"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVYls3jDONN1"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8JzSYTbONN1"
      },
      "outputs": [],
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
        "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEnDJNcsONN1"
      },
      "outputs": [],
      "source": [
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ6oZ3-zONN2"
      },
      "outputs": [],
      "source": [
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U7UgBRSONN2"
      },
      "outputs": [],
      "source": [
        "val_size = int(image_count * 0.2)\n",
        "train_ds = list_ds.skip(val_size)\n",
        "val_ds = list_ds.take(val_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29qB9Wb-ONN2"
      },
      "outputs": [],
      "source": [
        "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(tf.data.experimental.cardinality(val_ds).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoifVImiONN3"
      },
      "outputs": [],
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N5t6VGZONN3"
      },
      "outputs": [],
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqEYcg1DONN3"
      },
      "outputs": [],
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E39Isd9MONN4"
      },
      "outputs": [],
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvMDS77HONN4"
      },
      "outputs": [],
      "source": [
        "for image, label in train_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiopI8cYONN5"
      },
      "outputs": [],
      "source": [
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaNOOyZaONN5"
      },
      "outputs": [],
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCBwdzyYONN5"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLQVMrVMRV50"
      },
      "source": [
        "# Imagga"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r1CMeCCRYkJ"
      },
      "outputs": [],
      "source": [
        "# Setup a free account here: https://imagga.com/\n",
        "\n",
        "api_key =       'acc_00ee92774b1f02a'\n",
        "api_secret =    '9766b2d20da6d41bc961055e27d7fdc8'\n",
        "authorization = 'Basic YWNjXzAwZWU5Mjc3NGIxZjAyYTo5NzY2YjJkMjBkYTZkNDFiYzk2MTA1NWUyN2Q3ZmRjOA=='\n",
        "endpoint =      'https://api.imagga.com'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAMuzrTLVX2n",
        "outputId": "8a24b1a3-b76a-4576-d4e0-222954dae2d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"result\": {\n",
            "    \"tags\": [\n",
            "      {\n",
            "        \"confidence\": 31.8638324737549,\n",
            "        \"tag\": {\n",
            "          \"en\": \"people\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 31.5081062316895,\n",
            "        \"tag\": {\n",
            "          \"en\": \"person\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 29.9828586578369,\n",
            "        \"tag\": {\n",
            "          \"en\": \"adult\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 28.2731456756592,\n",
            "        \"tag\": {\n",
            "          \"en\": \"smiling\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 27.252965927124,\n",
            "        \"tag\": {\n",
            "          \"en\": \"nurse\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 26.6403732299805,\n",
            "        \"tag\": {\n",
            "          \"en\": \"attractive\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 26.4147453308105,\n",
            "        \"tag\": {\n",
            "          \"en\": \"businesswoman\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 25.1200046539307,\n",
            "        \"tag\": {\n",
            "          \"en\": \"happy\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 24.9628410339355,\n",
            "        \"tag\": {\n",
            "          \"en\": \"sitting\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 24.4328517913818,\n",
            "        \"tag\": {\n",
            "          \"en\": \"professional\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 24.3838653564453,\n",
            "        \"tag\": {\n",
            "          \"en\": \"work\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 22.7932167053223,\n",
            "        \"tag\": {\n",
            "          \"en\": \"confident\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 20.928560256958,\n",
            "        \"tag\": {\n",
            "          \"en\": \"office\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 20.2499809265137,\n",
            "        \"tag\": {\n",
            "          \"en\": \"indoors\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 20.1027965545654,\n",
            "        \"tag\": {\n",
            "          \"en\": \"portrait\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 19.4783363342285,\n",
            "        \"tag\": {\n",
            "          \"en\": \"business\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 19.0196971893311,\n",
            "        \"tag\": {\n",
            "          \"en\": \"women\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.8793525695801,\n",
            "        \"tag\": {\n",
            "          \"en\": \"coat\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.8308506011963,\n",
            "        \"tag\": {\n",
            "          \"en\": \"lifestyle\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.7337894439697,\n",
            "        \"tag\": {\n",
            "          \"en\": \"cheerful\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.6721343994141,\n",
            "        \"tag\": {\n",
            "          \"en\": \"two\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.6429195404053,\n",
            "        \"tag\": {\n",
            "          \"en\": \"patient\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.485034942627,\n",
            "        \"tag\": {\n",
            "          \"en\": \"laptop\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.2231044769287,\n",
            "        \"tag\": {\n",
            "          \"en\": \"education\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.0989990234375,\n",
            "        \"tag\": {\n",
            "          \"en\": \"talking\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 17.848123550415,\n",
            "        \"tag\": {\n",
            "          \"en\": \"computer\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 17.5554084777832,\n",
            "        \"tag\": {\n",
            "          \"en\": \"lab coat\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 17.529468536377,\n",
            "        \"tag\": {\n",
            "          \"en\": \"pretty\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 17.4145088195801,\n",
            "        \"tag\": {\n",
            "          \"en\": \"student\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 16.8450965881348,\n",
            "        \"tag\": {\n",
            "          \"en\": \"job\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 16.3583698272705,\n",
            "        \"tag\": {\n",
            "          \"en\": \"corporate\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 16.1646213531494,\n",
            "        \"tag\": {\n",
            "          \"en\": \"color\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 15.9225759506226,\n",
            "        \"tag\": {\n",
            "          \"en\": \"executive\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 15.6110219955444,\n",
            "        \"tag\": {\n",
            "          \"en\": \"table\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 15.4543046951294,\n",
            "        \"tag\": {\n",
            "          \"en\": \"sibling\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 15.1880855560303,\n",
            "        \"tag\": {\n",
            "          \"en\": \"home\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.8890180587769,\n",
            "        \"tag\": {\n",
            "          \"en\": \"holding\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.875452041626,\n",
            "        \"tag\": {\n",
            "          \"en\": \"technology\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.6897478103638,\n",
            "        \"tag\": {\n",
            "          \"en\": \"child\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.5388641357422,\n",
            "        \"tag\": {\n",
            "          \"en\": \"group\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.2822504043579,\n",
            "        \"tag\": {\n",
            "          \"en\": \"smile\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.1729955673218,\n",
            "        \"tag\": {\n",
            "          \"en\": \"working\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.1412420272827,\n",
            "        \"tag\": {\n",
            "          \"en\": \"man\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.1189823150635,\n",
            "        \"tag\": {\n",
            "          \"en\": \"friends\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.0494108200073,\n",
            "        \"tag\": {\n",
            "          \"en\": \"together\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.823676109314,\n",
            "        \"tag\": {\n",
            "          \"en\": \"lady\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.6973266601562,\n",
            "        \"tag\": {\n",
            "          \"en\": \"children\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.657301902771,\n",
            "        \"tag\": {\n",
            "          \"en\": \"male\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.6254167556763,\n",
            "        \"tag\": {\n",
            "          \"en\": \"looking\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.467791557312,\n",
            "        \"tag\": {\n",
            "          \"en\": \"team\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.4110765457153,\n",
            "        \"tag\": {\n",
            "          \"en\": \"daughter\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.3139228820801,\n",
            "        \"tag\": {\n",
            "          \"en\": \"businesspeople\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.1772794723511,\n",
            "        \"tag\": {\n",
            "          \"en\": \"learning\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.8614225387573,\n",
            "        \"tag\": {\n",
            "          \"en\": \"occupation\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.83824634552,\n",
            "        \"tag\": {\n",
            "          \"en\": \"successful\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.779257774353,\n",
            "        \"tag\": {\n",
            "          \"en\": \"mother\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.5941028594971,\n",
            "        \"tag\": {\n",
            "          \"en\": \"school\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.5333414077759,\n",
            "        \"tag\": {\n",
            "          \"en\": \"30s\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.3306446075439,\n",
            "        \"tag\": {\n",
            "          \"en\": \"adults\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.2433233261108,\n",
            "        \"tag\": {\n",
            "          \"en\": \"doctor\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.220290184021,\n",
            "        \"tag\": {\n",
            "          \"en\": \"couple\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.1045713424683,\n",
            "        \"tag\": {\n",
            "          \"en\": \"clothing\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.0997066497803,\n",
            "        \"tag\": {\n",
            "          \"en\": \"face\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.6942434310913,\n",
            "        \"tag\": {\n",
            "          \"en\": \"stethoscope\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.4995021820068,\n",
            "        \"tag\": {\n",
            "          \"en\": \"medical\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.3597078323364,\n",
            "        \"tag\": {\n",
            "          \"en\": \"desk\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.3313455581665,\n",
            "        \"tag\": {\n",
            "          \"en\": \"meeting\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.150390625,\n",
            "        \"tag\": {\n",
            "          \"en\": \"teamwork\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.0185213088989,\n",
            "        \"tag\": {\n",
            "          \"en\": \"20s\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.0087862014771,\n",
            "        \"tag\": {\n",
            "          \"en\": \"day\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.978816986084,\n",
            "        \"tag\": {\n",
            "          \"en\": \"indoor\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.9739141464233,\n",
            "        \"tag\": {\n",
            "          \"en\": \"classroom\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.962308883667,\n",
            "        \"tag\": {\n",
            "          \"en\": \"girls\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.7942485809326,\n",
            "        \"tag\": {\n",
            "          \"en\": \"blond\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.661150932312,\n",
            "        \"tag\": {\n",
            "          \"en\": \"teacher\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.4578037261963,\n",
            "        \"tag\": {\n",
            "          \"en\": \"college\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.1887464523315,\n",
            "        \"tag\": {\n",
            "          \"en\": \"casual\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.1625814437866,\n",
            "        \"tag\": {\n",
            "          \"en\": \"phone\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.143666267395,\n",
            "        \"tag\": {\n",
            "          \"en\": \"inside\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.0828037261963,\n",
            "        \"tag\": {\n",
            "          \"en\": \"worker\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.84448051452637,\n",
            "        \"tag\": {\n",
            "          \"en\": \"parent\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.74931049346924,\n",
            "        \"tag\": {\n",
            "          \"en\": \"sick person\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.73571872711182,\n",
            "        \"tag\": {\n",
            "          \"en\": \"colleagues\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.72682571411133,\n",
            "        \"tag\": {\n",
            "          \"en\": \"one\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.66145992279053,\n",
            "        \"tag\": {\n",
            "          \"en\": \"class\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.5580940246582,\n",
            "        \"tag\": {\n",
            "          \"en\": \"case\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.49493980407715,\n",
            "        \"tag\": {\n",
            "          \"en\": \"hospital\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.46806621551514,\n",
            "        \"tag\": {\n",
            "          \"en\": \"learn\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.42178153991699,\n",
            "        \"tag\": {\n",
            "          \"en\": \"happiness\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.36957359313965,\n",
            "        \"tag\": {\n",
            "          \"en\": \"double\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.16561222076416,\n",
            "        \"tag\": {\n",
            "          \"en\": \"friendly\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.13889503479004,\n",
            "        \"tag\": {\n",
            "          \"en\": \"teenager\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.86887836456299,\n",
            "        \"tag\": {\n",
            "          \"en\": \"success\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.8242769241333,\n",
            "        \"tag\": {\n",
            "          \"en\": \"medicine\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.82014179229736,\n",
            "        \"tag\": {\n",
            "          \"en\": \"casual clothing\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.7898645401001,\n",
            "        \"tag\": {\n",
            "          \"en\": \"restaurant\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.78658866882324,\n",
            "        \"tag\": {\n",
            "          \"en\": \"half length\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.78309440612793,\n",
            "        \"tag\": {\n",
            "          \"en\": \"consultant\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.76428699493408,\n",
            "        \"tag\": {\n",
            "          \"en\": \"secretary\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.69642925262451,\n",
            "        \"tag\": {\n",
            "          \"en\": \"daytime\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.63766765594482,\n",
            "        \"tag\": {\n",
            "          \"en\": \"exam\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.54083919525146,\n",
            "        \"tag\": {\n",
            "          \"en\": \"enjoying\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.53546905517578,\n",
            "        \"tag\": {\n",
            "          \"en\": \"females\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.53415584564209,\n",
            "        \"tag\": {\n",
            "          \"en\": \"youth\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.44671726226807,\n",
            "        \"tag\": {\n",
            "          \"en\": \"clothes\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.44334316253662,\n",
            "        \"tag\": {\n",
            "          \"en\": \"friendship\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.41549015045166,\n",
            "        \"tag\": {\n",
            "          \"en\": \"communication\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.40926933288574,\n",
            "        \"tag\": {\n",
            "          \"en\": \"study\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.39022541046143,\n",
            "        \"tag\": {\n",
            "          \"en\": \"horizontal\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.34784126281738,\n",
            "        \"tag\": {\n",
            "          \"en\": \"glasses\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.25311088562012,\n",
            "        \"tag\": {\n",
            "          \"en\": \"book\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.15342426300049,\n",
            "        \"tag\": {\n",
            "          \"en\": \"cup\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.12304019927979,\n",
            "        \"tag\": {\n",
            "          \"en\": \"employee\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.11534404754639,\n",
            "        \"tag\": {\n",
            "          \"en\": \"suit\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.96217012405396,\n",
            "        \"tag\": {\n",
            "          \"en\": \"businessman\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.84201002120972,\n",
            "        \"tag\": {\n",
            "          \"en\": \"boy\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.80004119873047,\n",
            "        \"tag\": {\n",
            "          \"en\": \"clinic\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.76276779174805,\n",
            "        \"tag\": {\n",
            "          \"en\": \"having\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.76250696182251,\n",
            "        \"tag\": {\n",
            "          \"en\": \"assistance\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.58378982543945,\n",
            "        \"tag\": {\n",
            "          \"en\": \"charming\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.5801854133606,\n",
            "        \"tag\": {\n",
            "          \"en\": \"sit\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.55086088180542,\n",
            "        \"tag\": {\n",
            "          \"en\": \"smart\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.51019811630249,\n",
            "        \"tag\": {\n",
            "          \"en\": \"room\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.46589279174805,\n",
            "        \"tag\": {\n",
            "          \"en\": \"manager\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.42555522918701,\n",
            "        \"tag\": {\n",
            "          \"en\": \"coffee\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.42033672332764,\n",
            "        \"tag\": {\n",
            "          \"en\": \"care\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.36455488204956,\n",
            "        \"tag\": {\n",
            "          \"en\": \"joyful\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.12694835662842,\n",
            "        \"tag\": {\n",
            "          \"en\": \"lovely\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.10574197769165,\n",
            "        \"tag\": {\n",
            "          \"en\": \"kid\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.09089612960815,\n",
            "        \"tag\": {\n",
            "          \"en\": \"interior\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.04806137084961,\n",
            "        \"tag\": {\n",
            "          \"en\": \"buddy\"\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"status\": {\n",
            "    \"text\": \"\",\n",
            "    \"type\": \"success\"\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"result\": {\n",
            "    \"tags\": [\n",
            "      {\n",
            "        \"confidence\": 100,\n",
            "        \"tag\": {\n",
            "          \"en\": \"child\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 55.0953598022461,\n",
            "        \"tag\": {\n",
            "          \"en\": \"kid\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 49.3938293457031,\n",
            "        \"tag\": {\n",
            "          \"en\": \"childhood\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 47.8244972229004,\n",
            "        \"tag\": {\n",
            "          \"en\": \"little\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 46.2606925964355,\n",
            "        \"tag\": {\n",
            "          \"en\": \"baby\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 44.8761711120605,\n",
            "        \"tag\": {\n",
            "          \"en\": \"face\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 44.6111869812012,\n",
            "        \"tag\": {\n",
            "          \"en\": \"cute\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 42.1782379150391,\n",
            "        \"tag\": {\n",
            "          \"en\": \"portrait\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 41.9575309753418,\n",
            "        \"tag\": {\n",
            "          \"en\": \"person\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 40.5681991577148,\n",
            "        \"tag\": {\n",
            "          \"en\": \"eyes\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 39.2753372192383,\n",
            "        \"tag\": {\n",
            "          \"en\": \"toddler\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 37.3602447509766,\n",
            "        \"tag\": {\n",
            "          \"en\": \"juvenile\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 33.3013305664062,\n",
            "        \"tag\": {\n",
            "          \"en\": \"happy\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 32.2579383850098,\n",
            "        \"tag\": {\n",
            "          \"en\": \"boy\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 30.5391998291016,\n",
            "        \"tag\": {\n",
            "          \"en\": \"adorable\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 27.5641403198242,\n",
            "        \"tag\": {\n",
            "          \"en\": \"smiling\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 27.497200012207,\n",
            "        \"tag\": {\n",
            "          \"en\": \"happiness\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 27.1522426605225,\n",
            "        \"tag\": {\n",
            "          \"en\": \"smile\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 26.5215492248535,\n",
            "        \"tag\": {\n",
            "          \"en\": \"expression\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 26.4925746917725,\n",
            "        \"tag\": {\n",
            "          \"en\": \"children\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 26.1568851470947,\n",
            "        \"tag\": {\n",
            "          \"en\": \"sweet\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 24.1839904785156,\n",
            "        \"tag\": {\n",
            "          \"en\": \"infant\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 24.0478248596191,\n",
            "        \"tag\": {\n",
            "          \"en\": \"people\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 23.258415222168,\n",
            "        \"tag\": {\n",
            "          \"en\": \"looking\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 22.1757164001465,\n",
            "        \"tag\": {\n",
            "          \"en\": \"innocence\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 21.3278179168701,\n",
            "        \"tag\": {\n",
            "          \"en\": \"innocent\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 20.77370262146,\n",
            "        \"tag\": {\n",
            "          \"en\": \"kids\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 20.6312141418457,\n",
            "        \"tag\": {\n",
            "          \"en\": \"care\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 20.4741992950439,\n",
            "        \"tag\": {\n",
            "          \"en\": \"newborn\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 20.3713550567627,\n",
            "        \"tag\": {\n",
            "          \"en\": \"cheerful\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 19.6364002227783,\n",
            "        \"tag\": {\n",
            "          \"en\": \"youth\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 19.4654312133789,\n",
            "        \"tag\": {\n",
            "          \"en\": \"one\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.7606010437012,\n",
            "        \"tag\": {\n",
            "          \"en\": \"fun\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.5317211151123,\n",
            "        \"tag\": {\n",
            "          \"en\": \"daughter\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.4265518188477,\n",
            "        \"tag\": {\n",
            "          \"en\": \"joy\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 18.1978168487549,\n",
            "        \"tag\": {\n",
            "          \"en\": \"love\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 17.4083290100098,\n",
            "        \"tag\": {\n",
            "          \"en\": \"son\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 17.2158317565918,\n",
            "        \"tag\": {\n",
            "          \"en\": \"blond\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 16.8461856842041,\n",
            "        \"tag\": {\n",
            "          \"en\": \"head\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 16.6896743774414,\n",
            "        \"tag\": {\n",
            "          \"en\": \"hair\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 16.5410823822021,\n",
            "        \"tag\": {\n",
            "          \"en\": \"human\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 16.1355228424072,\n",
            "        \"tag\": {\n",
            "          \"en\": \"male\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 16.1109085083008,\n",
            "        \"tag\": {\n",
            "          \"en\": \"offspring\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 15.4353132247925,\n",
            "        \"tag\": {\n",
            "          \"en\": \"pretty\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.546911239624,\n",
            "        \"tag\": {\n",
            "          \"en\": \"skin\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 14.2667970657349,\n",
            "        \"tag\": {\n",
            "          \"en\": \"family\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.7114372253418,\n",
            "        \"tag\": {\n",
            "          \"en\": \"girls\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 13.2415819168091,\n",
            "        \"tag\": {\n",
            "          \"en\": \"braid\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.9408874511719,\n",
            "        \"tag\": {\n",
            "          \"en\": \"emotion\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.6342906951904,\n",
            "        \"tag\": {\n",
            "          \"en\": \"life\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.2527313232422,\n",
            "        \"tag\": {\n",
            "          \"en\": \"mouth\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 12.0023412704468,\n",
            "        \"tag\": {\n",
            "          \"en\": \"healthy\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.9775419235229,\n",
            "        \"tag\": {\n",
            "          \"en\": \"joyful\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.4898271560669,\n",
            "        \"tag\": {\n",
            "          \"en\": \"closeup\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.4476346969604,\n",
            "        \"tag\": {\n",
            "          \"en\": \"close\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.4257011413574,\n",
            "        \"tag\": {\n",
            "          \"en\": \"hand\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.37366771698,\n",
            "        \"tag\": {\n",
            "          \"en\": \"playful\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 11.2293100357056,\n",
            "        \"tag\": {\n",
            "          \"en\": \"play\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.3346948623657,\n",
            "        \"tag\": {\n",
            "          \"en\": \"sitting\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.2969694137573,\n",
            "        \"tag\": {\n",
            "          \"en\": \"outside\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 10.0563468933105,\n",
            "        \"tag\": {\n",
            "          \"en\": \"playing\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.92040634155273,\n",
            "        \"tag\": {\n",
            "          \"en\": \"mother\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.90316772460938,\n",
            "        \"tag\": {\n",
            "          \"en\": \"studio\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.80482387542725,\n",
            "        \"tag\": {\n",
            "          \"en\": \"lovely\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.51257228851318,\n",
            "        \"tag\": {\n",
            "          \"en\": \"grass\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.47481918334961,\n",
            "        \"tag\": {\n",
            "          \"en\": \"laughing\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 9.10533142089844,\n",
            "        \"tag\": {\n",
            "          \"en\": \"holding\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.78421115875244,\n",
            "        \"tag\": {\n",
            "          \"en\": \"look\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.56437873840332,\n",
            "        \"tag\": {\n",
            "          \"en\": \"bed\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.38336944580078,\n",
            "        \"tag\": {\n",
            "          \"en\": \"pink\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.3597936630249,\n",
            "        \"tag\": {\n",
            "          \"en\": \"health\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.28606986999512,\n",
            "        \"tag\": {\n",
            "          \"en\": \"funny\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.1355504989624,\n",
            "        \"tag\": {\n",
            "          \"en\": \"soft\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 8.0682258605957,\n",
            "        \"tag\": {\n",
            "          \"en\": \"eye\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.89725685119629,\n",
            "        \"tag\": {\n",
            "          \"en\": \"babies\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.71735620498657,\n",
            "        \"tag\": {\n",
            "          \"en\": \"attractive\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.68386602401733,\n",
            "        \"tag\": {\n",
            "          \"en\": \"old\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.65086889266968,\n",
            "        \"tag\": {\n",
            "          \"en\": \"loving\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.59133338928223,\n",
            "        \"tag\": {\n",
            "          \"en\": \"eating\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.48542070388794,\n",
            "        \"tag\": {\n",
            "          \"en\": \"outdoors\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.36806869506836,\n",
            "        \"tag\": {\n",
            "          \"en\": \"parent\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.30834913253784,\n",
            "        \"tag\": {\n",
            "          \"en\": \"new\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 7.02019739151001,\n",
            "        \"tag\": {\n",
            "          \"en\": \"model\"\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"status\": {\n",
            "    \"text\": \"\",\n",
            "    \"type\": \"success\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "url = 'https://api.imagga.com/v2/tags/?image_url=https://www.ishelp.info/data/images/'\n",
        "images = ['3_628913364622688256.jpg', '3_628933195636047872.jpg']\n",
        "\n",
        "for image in images:\n",
        "  request = requests.get(url + image, auth=(api_key, api_secret))\n",
        "  json_data = json.loads(request.text)\n",
        "  clean_data = json.dumps(json_data, indent=2)\n",
        "  print(f\"{clean_data}\")\n",
        "\n",
        "  # tag = the entity found in the image\n",
        "  # confidence = ranges from 0 to 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_fXpsPYXZ9N",
        "outputId": "fefdc3da-265a-4797-8851-aa212aa03102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"result\": {\n",
            "    \"categorizers\": [\n",
            "      {\n",
            "        \"id\": \"general_v3\",\n",
            "        \"labels\": [\n",
            "          \"\"\n",
            "        ],\n",
            "        \"title\": \"general_v3\"\n",
            "      },\n",
            "      {\n",
            "        \"id\": \"nsfw_beta\",\n",
            "        \"labels\": [\n",
            "          \"nsfw\",\n",
            "          \"safe\",\n",
            "          \"underwear\"\n",
            "        ],\n",
            "        \"title\": \"NSFW Categorizer (beta v2)\"\n",
            "      },\n",
            "      {\n",
            "        \"id\": \"personal_photos\",\n",
            "        \"labels\": [\n",
            "          \"interior objects\",\n",
            "          \"nature landscape\",\n",
            "          \"beaches seaside\",\n",
            "          \"events parties\",\n",
            "          \"food drinks\",\n",
            "          \"paintings art\",\n",
            "          \"pets animals\",\n",
            "          \"text visuals\",\n",
            "          \"sunrises sunsets\",\n",
            "          \"cars vehicles\",\n",
            "          \"macro flowers\",\n",
            "          \"streetview architecture\",\n",
            "          \"people portraits\"\n",
            "        ],\n",
            "        \"title\": \"Personal Photos Categorizer\"\n",
            "      },\n",
            "      {\n",
            "        \"id\": \"realestate_dwellings\",\n",
            "        \"labels\": [\n",
            "          \"Airey house\",\n",
            "          \"Assam-type house\",\n",
            "          \"Brownstone\",\n",
            "          \"Bungalow\",\n",
            "          \"Cape Cod\",\n",
            "          \"Colonial\",\n",
            "          \"Conch house\",\n",
            "          \"Converted Barn\",\n",
            "          \"Cottage\",\n",
            "          \"Craftsman\",\n",
            "          \"Dacha\",\n",
            "          \"Farmhouse\",\n",
            "          \"Georgian\",\n",
            "          \"Hanok\",\n",
            "          \"Houseboat\",\n",
            "          \"Igloo\",\n",
            "          \"Izba\",\n",
            "          \"Log cabin\",\n",
            "          \"Mansion\",\n",
            "          \"Manufactured House\",\n",
            "          \"Minka\",\n",
            "          \"Park home Mobile home\",\n",
            "          \"Penthouse\",\n",
            "          \"Ranch\",\n",
            "          \"Terraced house\",\n",
            "          \"Tower block\",\n",
            "          \" Apartment tower\",\n",
            "          \"Town House\",\n",
            "          \"Tree house\",\n",
            "          \"Yurt\"\n",
            "        ],\n",
            "        \"title\": \"Real Estate - Dwellings Categorizer\"\n",
            "      },\n",
            "      {\n",
            "        \"id\": \"realestate_rooms\",\n",
            "        \"labels\": [\n",
            "          \"Attic\",\n",
            "          \"Back yard\",\n",
            "          \"Basement\",\n",
            "          \"Bathroom\",\n",
            "          \"Bedroom\",\n",
            "          \"Billard room\",\n",
            "          \"Closet\",\n",
            "          \"Dining room\",\n",
            "          \"Entryway\",\n",
            "          \"Front yard\",\n",
            "          \"Garage\",\n",
            "          \"Home office\",\n",
            "          \"Kitchen\",\n",
            "          \"Laundry room\",\n",
            "          \"Library\",\n",
            "          \"Living room\",\n",
            "          \"Loft\",\n",
            "          \"Mud room\",\n",
            "          \"Nursery\",\n",
            "          \"Pantry\",\n",
            "          \"Patio\",\n",
            "          \"Playroom\",\n",
            "          \"Porch\",\n",
            "          \"Sauna\",\n",
            "          \"Screened porch\",\n",
            "          \"Staircase\",\n",
            "          \"Sunroom\",\n",
            "          \"Wine Cellar\",\n",
            "          \"Workshop\"\n",
            "        ],\n",
            "        \"title\": \"Real Estate - Rooms Categorizer\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"status\": {\n",
            "    \"text\": \"\",\n",
            "    \"type\": \"success\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = requests.get('https://api.imagga.com/v2/categorizers', auth=(api_key, api_secret))\n",
        "json_data = json.loads(response.text)\n",
        "clean_data = json.dumps(json_data, indent=2)\n",
        "print(f\"{clean_data}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n6Z_ry0rn1Mx",
        "outputId": "5ccac8ac-f760-4641-9c86-37eabbe1ff69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"result\": {\n",
            "    \"categories\": [\n",
            "      {\n",
            "        \"confidence\": 78.2220153808594,\n",
            "        \"name\": {\n",
            "          \"en\": \"people portraits\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 16.2230091094971,\n",
            "        \"name\": {\n",
            "          \"en\": \"paintings art\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 2.56214904785156,\n",
            "        \"name\": {\n",
            "          \"en\": \"pets animals\"\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"status\": {\n",
            "    \"text\": \"\",\n",
            "    \"type\": \"success\"\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"result\": {\n",
            "    \"categories\": [\n",
            "      {\n",
            "        \"confidence\": 73.7639312744141,\n",
            "        \"name\": {\n",
            "          \"en\": \"people portraits\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 24.0428619384766,\n",
            "        \"name\": {\n",
            "          \"en\": \"paintings art\"\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"confidence\": 2.0138156414032,\n",
            "        \"name\": {\n",
            "          \"en\": \"pets animals\"\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"status\": {\n",
            "    \"text\": \"\",\n",
            "    \"type\": \"success\"\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-815ed756-93de-47e1-ad97-6087d11c55f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interior objects</th>\n",
              "      <th>nature landscape</th>\n",
              "      <th>beaches seaside</th>\n",
              "      <th>events parties</th>\n",
              "      <th>food drinks</th>\n",
              "      <th>paintings art</th>\n",
              "      <th>pets animals</th>\n",
              "      <th>text visuals</th>\n",
              "      <th>sunrises sunsets</th>\n",
              "      <th>cars vehicles</th>\n",
              "      <th>macro flowers</th>\n",
              "      <th>streetview architecture</th>\n",
              "      <th>people portraits</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3_628913364622688256.jpg</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.223009</td>\n",
              "      <td>2.562149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.222015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_628933195636047872.jpg</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.042862</td>\n",
              "      <td>2.013816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.763931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-815ed756-93de-47e1-ad97-6087d11c55f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-815ed756-93de-47e1-ad97-6087d11c55f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-815ed756-93de-47e1-ad97-6087d11c55f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19c71454-3073-44f7-9fe1-7967f4d26255\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19c71454-3073-44f7-9fe1-7967f4d26255')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19c71454-3073-44f7-9fe1-7967f4d26255 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                          interior objects  nature landscape  beaches seaside  \\\n",
              "3_628913364622688256.jpg               0.0               0.0              0.0   \n",
              "3_628933195636047872.jpg               0.0               0.0              0.0   \n",
              "\n",
              "                          events parties  food drinks  paintings art  \\\n",
              "3_628913364622688256.jpg             0.0          0.0      16.223009   \n",
              "3_628933195636047872.jpg             0.0          0.0      24.042862   \n",
              "\n",
              "                          pets animals  text visuals  sunrises sunsets  \\\n",
              "3_628913364622688256.jpg      2.562149           0.0               0.0   \n",
              "3_628933195636047872.jpg      2.013816           0.0               0.0   \n",
              "\n",
              "                          cars vehicles  macro flowers  \\\n",
              "3_628913364622688256.jpg            0.0            0.0   \n",
              "3_628933195636047872.jpg            0.0            0.0   \n",
              "\n",
              "                          streetview architecture  people portraits  \n",
              "3_628913364622688256.jpg                      0.0         78.222015  \n",
              "3_628933195636047872.jpg                      0.0         73.763931  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(columns=[\"interior objects\", \"nature landscape\", \"beaches seaside\", \"events parties\", \"food drinks\",\n",
        "                           \"paintings art\", \"pets animals\", \"text visuals\", \"sunrises sunsets\", \"cars vehicles\",\n",
        "                           \"macro flowers\", \"streetview architecture\", \"people portraits\"])\n",
        "\n",
        "url = 'https://api.imagga.com/v2/categories/personal_photos/?image_url=https://www.ishelp.info/data/images/'\n",
        "images = ['3_628913364622688256.jpg', '3_628933195636047872.jpg']\n",
        "\n",
        "for image in images:\n",
        "  request = requests.get(url + image, auth=(api_key, api_secret))\n",
        "  json_data = json.loads(request.text)\n",
        "  print(json.dumps(json_data, indent=2))\n",
        "\n",
        "  # Create a list of 0.0 scores to update as we get data for each category we want to score in our DataFrame\n",
        "  scores = [0.0] * len(df.columns)\n",
        "\n",
        "  # Iterate through each category of the result\n",
        "  for category in json_data[\"result\"][\"categories\"]:\n",
        "    # Find the associated column in the DataFrame\n",
        "    for n, col in enumerate(df.columns):\n",
        "      if col == category['name']['en']:\n",
        "        # Store the score\n",
        "        scores[n] = category['confidence']\n",
        "        break # No need to keep looping once we've found the score\n",
        "\n",
        "    # Store the list as a new row in the DataFrame\n",
        "    df.loc[image] = scores\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRdXr51wpGej"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9NzdP_OtONNs",
        "QmQqi0Z1ONNs",
        "7wWq-euSONNv"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
